{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10689716,"sourceType":"datasetVersion","datasetId":6623322},{"sourceId":11156898,"sourceType":"datasetVersion","datasetId":6961175}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":2785.681046,"end_time":"2025-03-19T19:57:32.152387","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-19T19:11:06.471341","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport csv\nimport time","metadata":{"_uuid":"4c823a1f-7c61-41fc-a360-8f011eac79f5","_cell_guid":"56e71f38-8608-4a6f-a4d5-53f7f93559c0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:17.879475Z","iopub.execute_input":"2025-03-25T10:10:17.879831Z","iopub.status.idle":"2025-03-25T10:10:22.360543Z","shell.execute_reply.started":"2025-03-25T10:10:17.879799Z","shell.execute_reply":"2025-03-25T10:10:22.359333Z"},"papermill":{"duration":3.027677,"end_time":"2025-03-19T19:11:12.117968","exception":false,"start_time":"2025-03-19T19:11:09.090291","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load the Dataset\ntext = \"\"\nwith open(\"/kaggle/input/poem-100/poems-100 - poems-100.csv\", \"r\") as file:\n    reader = csv.reader(file)\n    for row in reader:\n        text += \" \".join(row) + \" \"                          # Combine All Lines into a Single Text","metadata":{"_uuid":"8c2678ad-ee2b-4a04-8855-bfdb51a0f038","_cell_guid":"6c46717b-0c9d-433b-884f-a06dfbabe436","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:41.776860Z","iopub.execute_input":"2025-03-25T10:10:41.777232Z","iopub.status.idle":"2025-03-25T10:10:41.794258Z","shell.execute_reply.started":"2025-03-25T10:10:41.777196Z","shell.execute_reply":"2025-03-25T10:10:41.792952Z"},"papermill":{"duration":0.027475,"end_time":"2025-03-19T19:11:12.152186","exception":false,"start_time":"2025-03-19T19:11:12.124711","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Tokenize the Text into Words\ntokens = text.split()","metadata":{"_uuid":"4c86cfd2-cf8f-4d2e-b33c-ba025c43be4b","_cell_guid":"38b839ef-357b-4a22-b41b-22044816f3a2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:41.993216Z","iopub.execute_input":"2025-03-25T10:10:41.993591Z","iopub.status.idle":"2025-03-25T10:10:42.001173Z","shell.execute_reply.started":"2025-03-25T10:10:41.993554Z","shell.execute_reply":"2025-03-25T10:10:41.999645Z"},"papermill":{"duration":0.009746,"end_time":"2025-03-19T19:11:12.165174","exception":false,"start_time":"2025-03-19T19:11:12.155428","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Create a Dictionary to Map Words to Indices\nword_to_idx = {}\nidx_to_word = {}\nvocab_size = 0\n\nfor word in tokens:\n    if word not in word_to_idx:\n        word_to_idx[word] = vocab_size\n        idx_to_word[vocab_size] = word\n        vocab_size += 1","metadata":{"_uuid":"869c4bf5-4e10-49af-a58a-6d789bcd2d38","_cell_guid":"d33b978b-b424-4c7c-a958-fc1bc9247488","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:42.181027Z","iopub.execute_input":"2025-03-25T10:10:42.181368Z","iopub.status.idle":"2025-03-25T10:10:42.194079Z","shell.execute_reply.started":"2025-03-25T10:10:42.181341Z","shell.execute_reply":"2025-03-25T10:10:42.192767Z"},"papermill":{"duration":0.012758,"end_time":"2025-03-19T19:11:12.180766","exception":false,"start_time":"2025-03-19T19:11:12.168008","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Convert Tokens to Indices\ntoken_indices = [word_to_idx[word] for word in tokens]","metadata":{"_uuid":"279b60c5-a0d0-4863-871c-bff59281cd5c","_cell_guid":"c9cd5cba-f852-4973-b0dc-8d66baa49468","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:42.356576Z","iopub.execute_input":"2025-03-25T10:10:42.356967Z","iopub.status.idle":"2025-03-25T10:10:42.364484Z","shell.execute_reply.started":"2025-03-25T10:10:42.356934Z","shell.execute_reply":"2025-03-25T10:10:42.363212Z"},"papermill":{"duration":0.009722,"end_time":"2025-03-19T19:11:12.193441","exception":false,"start_time":"2025-03-19T19:11:12.183719","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Create Sequences and Targets\nseq_length = 10\nsequences = []\ntargets = []\n\nfor i in range(len(token_indices) - seq_length):\n    seq = token_indices[i:i + seq_length]\n    target = token_indices[i + seq_length]\n    sequences.append(seq)\n    targets.append(target)","metadata":{"_uuid":"59def609-073e-4701-8018-389835efd44d","_cell_guid":"f55f7382-ee93-49c1-9920-d361544a7306","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:42.527013Z","iopub.execute_input":"2025-03-25T10:10:42.527361Z","iopub.status.idle":"2025-03-25T10:10:42.659927Z","shell.execute_reply.started":"2025-03-25T10:10:42.527334Z","shell.execute_reply":"2025-03-25T10:10:42.658236Z"},"papermill":{"duration":0.110969,"end_time":"2025-03-19T19:11:12.308718","exception":false,"start_time":"2025-03-19T19:11:12.197749","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Convert to PyTorch Tensors\nsequences = torch.tensor(sequences, dtype = torch.long)\ntargets = torch.tensor(targets, dtype = torch.long)","metadata":{"_uuid":"15e68342-313b-418a-be41-a9fb34dbb31c","_cell_guid":"ea8c0411-e90c-4db5-b55d-4213a135ec7a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:42.710004Z","iopub.execute_input":"2025-03-25T10:10:42.710381Z","iopub.status.idle":"2025-03-25T10:10:42.758157Z","shell.execute_reply.started":"2025-03-25T10:10:42.710347Z","shell.execute_reply":"2025-03-25T10:10:42.757148Z"},"papermill":{"duration":0.063034,"end_time":"2025-03-19T19:11:12.375051","exception":false,"start_time":"2025-03-19T19:11:12.312017","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Define One-Hot Encoding for RNN Model\nclass OneHotRNN(nn.Module):\n    def __init__(self, vocab_size, hidden_dim, output_dim):\n        super(OneHotRNN, self).__init__()\n        self.rnn = nn.RNN(vocab_size, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        output, _ = self.rnn(x)\n        out = self.fc(output[:, -1, :])\n        return out","metadata":{"_uuid":"d95e9405-f7d8-43aa-9a66-954416352c9c","_cell_guid":"76eff407-911d-42b0-956f-ac17dcc47607","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:42.876716Z","iopub.execute_input":"2025-03-25T10:10:42.877101Z","iopub.status.idle":"2025-03-25T10:10:42.883060Z","shell.execute_reply.started":"2025-03-25T10:10:42.877069Z","shell.execute_reply":"2025-03-25T10:10:42.881713Z"},"papermill":{"duration":0.00879,"end_time":"2025-03-19T19:11:12.387015","exception":false,"start_time":"2025-03-19T19:11:12.378225","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Define One-Hot Encoding for LSTM Model\nclass OneHotLSTM(nn.Module):\n    def __init__(self, vocab_size, hidden_dim, output_dim):\n        super(OneHotLSTM, self).__init__()\n        self.lstm = nn.LSTM(vocab_size, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        output, _ = self.lstm(x)\n        out = self.fc(output[:, -1, :])\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T10:10:43.024609Z","iopub.execute_input":"2025-03-25T10:10:43.025018Z","iopub.status.idle":"2025-03-25T10:10:43.031205Z","shell.execute_reply.started":"2025-03-25T10:10:43.024972Z","shell.execute_reply":"2025-03-25T10:10:43.030026Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Define Embedding for RNN Model\nclass EmbeddingRNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n        super(EmbeddingRNN, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        output, _ = self.rnn(x)\n        out = self.fc(output[:, -1, :])\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T10:10:43.208462Z","iopub.execute_input":"2025-03-25T10:10:43.208882Z","iopub.status.idle":"2025-03-25T10:10:43.215858Z","shell.execute_reply.started":"2025-03-25T10:10:43.208848Z","shell.execute_reply":"2025-03-25T10:10:43.214553Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Define Embedding for LSTM Model\nclass EmbeddingLSTM(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n        super(EmbeddingLSTM, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        output, _ = self.lstm(x)\n        out = self.fc(output[:, -1, :])\n        return out","metadata":{"_uuid":"10e20d65-4ffe-41da-829e-836dd87e8bf7","_cell_guid":"e38109cb-ac69-434f-a3a7-d886b2804eb3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:43.398440Z","iopub.execute_input":"2025-03-25T10:10:43.399020Z","iopub.status.idle":"2025-03-25T10:10:43.405859Z","shell.execute_reply.started":"2025-03-25T10:10:43.398973Z","shell.execute_reply":"2025-03-25T10:10:43.404620Z"},"papermill":{"duration":0.008483,"end_time":"2025-03-19T19:11:12.398403","exception":false,"start_time":"2025-03-19T19:11:12.389920","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Hyperparameters\nembed_dim = 100\nhidden_dim = 128\noutput_dim = vocab_size","metadata":{"_uuid":"2d842c6a-d8e6-4ab4-99a0-1da35f7f3b90","_cell_guid":"c1616550-d69f-44c3-90e0-dd83d6fce72a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:43.592142Z","iopub.execute_input":"2025-03-25T10:10:43.592527Z","iopub.status.idle":"2025-03-25T10:10:43.597105Z","shell.execute_reply.started":"2025-03-25T10:10:43.592466Z","shell.execute_reply":"2025-03-25T10:10:43.596012Z"},"papermill":{"duration":0.007204,"end_time":"2025-03-19T19:11:12.408594","exception":false,"start_time":"2025-03-19T19:11:12.401390","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Initialize Models\nonehot_rnn = OneHotRNN(vocab_size, hidden_dim, output_dim)\nonehot_lstm = OneHotLSTM(vocab_size, hidden_dim, output_dim)\nembedding_rnn = EmbeddingRNN(vocab_size, embed_dim, hidden_dim, output_dim)\nembedding_lstm = EmbeddingLSTM(vocab_size, embed_dim, hidden_dim, output_dim)","metadata":{"_uuid":"50558562-a108-4908-b4a3-33f55cc5cfc8","_cell_guid":"1ed3d7bb-ee0a-4ee0-abe2-6db10d919375","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:46.793732Z","iopub.execute_input":"2025-03-25T10:10:46.794113Z","iopub.status.idle":"2025-03-25T10:10:46.929132Z","shell.execute_reply.started":"2025-03-25T10:10:46.794081Z","shell.execute_reply":"2025-03-25T10:10:46.927984Z"},"papermill":{"duration":0.058866,"end_time":"2025-03-19T19:11:12.470427","exception":false,"start_time":"2025-03-19T19:11:12.411561","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Optimizers\ncriterion = nn.CrossEntropyLoss()\nonehot_rnn_optimizer = optim.Adam(onehot_rnn.parameters(), lr=0.001)\nonehot_lstm_optimizer = optim.Adam(onehot_lstm.parameters(), lr=0.001)\nembedding_rnn_optimizer = optim.Adam(embedding_rnn.parameters(), lr=0.001)\nembedding_lstm_optimizer = optim.Adam(embedding_lstm.parameters(), lr=0.001)","metadata":{"_uuid":"99dbbd3b-bbc3-40c3-beda-9c508ff327bc","_cell_guid":"7c3635c6-8615-4006-a7bf-afd5f502d856","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:47.007804Z","iopub.execute_input":"2025-03-25T10:10:47.008156Z","iopub.status.idle":"2025-03-25T10:10:49.733680Z","shell.execute_reply.started":"2025-03-25T10:10:47.008129Z","shell.execute_reply":"2025-03-25T10:10:49.732473Z"},"papermill":{"duration":3.44091,"end_time":"2025-03-19T19:11:15.914406","exception":false,"start_time":"2025-03-19T19:11:12.473496","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Loss Tracking\nonehot_rnn_losses, onehot_lstm_losses, embedding_rnn_losses, embedding_lstm_losses = [], [], [], []","metadata":{"_uuid":"ab8b1332-a868-4631-9b0a-22d626338ce4","_cell_guid":"69055478-5691-41ac-a95f-91670f7d32ad","trusted":true,"collapsed":false,"papermill":{"duration":0.008272,"end_time":"2025-03-19T19:11:15.926018","exception":false,"start_time":"2025-03-19T19:11:15.917746","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-25T10:10:49.735078Z","iopub.execute_input":"2025-03-25T10:10:49.735624Z","iopub.status.idle":"2025-03-25T10:10:49.741588Z","shell.execute_reply.started":"2025-03-25T10:10:49.735586Z","shell.execute_reply":"2025-03-25T10:10:49.740109Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Training Function with Tracking\ndef train_model(model, optimizer, name):\n    start_time = time.time()\n    for epoch in range(70):\n        total_loss = 0\n        for i in range(0, len(sequences), 32):\n            batch_seq = sequences[i:i + 32]\n            batch_target = targets[i:i + 32]\n\n            # One-Hot Encoding for OneHot Models\n            if \"OneHot\" in name:\n                batch_seq = F.one_hot(batch_seq, num_classes=vocab_size).float()\n\n            # Forward Pass\n            outputs = model(batch_seq)\n            loss = criterion(outputs, batch_target)\n\n            # Backward Pass and Optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        avg_loss = total_loss / (len(sequences) // 32)\n        if name == \"OneHotRNN\":\n            onehot_rnn_losses.append(avg_loss)\n        elif name == \"OneHotLSTM\":\n            onehot_lstm_losses.append(avg_loss)\n        elif name == \"EmbeddingRNN\":\n            embedding_rnn_losses.append(avg_loss)\n        else:\n            embedding_lstm_losses.append(avg_loss)\n\n        print(f\"{name} Epoch [{epoch+1}/70], Avg Loss: {avg_loss:.4f}\")\n    print(f\"{name} Training Time: {time.time() - start_time:.2f}s\\n\")","metadata":{"_uuid":"040f1d19-bffc-4b28-8c35-4763548cb1a1","_cell_guid":"5176b817-1143-4dca-a5b8-a74d12dc5c18","trusted":true,"collapsed":false,"papermill":{"duration":0.009742,"end_time":"2025-03-19T19:11:15.938867","exception":false,"start_time":"2025-03-19T19:11:15.929125","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-25T10:10:49.743390Z","iopub.execute_input":"2025-03-25T10:10:49.743865Z","iopub.status.idle":"2025-03-25T10:10:49.771173Z","shell.execute_reply.started":"2025-03-25T10:10:49.743809Z","shell.execute_reply":"2025-03-25T10:10:49.769414Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Poem Generation Function\ndef generate_poem(model, seed_text, num_words=50, model_type=\"EmbeddingLSTM\"):\n    model.eval()\n    words = seed_text.split()\n    with torch.no_grad():\n        for _ in range(num_words):\n            seq = [word_to_idx.get(word, 0) for word in words[-seq_length:]]\n            seq = torch.tensor(seq, dtype=torch.long).unsqueeze(0)\n\n            if \"OneHot\" in model_type:\n                seq = F.one_hot(seq, num_classes=vocab_size).float()\n\n            output = model(seq)\n            probabilities = F.softmax(output, dim=1)\n            predicted_idx = torch.multinomial(probabilities, 1).item()\n            words.append(idx_to_word[predicted_idx])\n\n    return \" \".join(words)","metadata":{"_uuid":"7f964834-8214-4cbd-993b-d2b0b8bcb943","_cell_guid":"e592963b-6d35-44af-9bef-c01aace33f64","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:53.347344Z","iopub.execute_input":"2025-03-25T10:10:53.347756Z","iopub.status.idle":"2025-03-25T10:10:53.355111Z","shell.execute_reply.started":"2025-03-25T10:10:53.347720Z","shell.execute_reply":"2025-03-25T10:10:53.353557Z"},"papermill":{"duration":0.01001,"end_time":"2025-03-19T19:11:15.951971","exception":false,"start_time":"2025-03-19T19:11:15.941961","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Train All Models\ntrain_model(onehot_rnn, onehot_rnn_optimizer, \"OneHotRNN\")","metadata":{"_uuid":"81314e2b-8a3e-48c4-a312-7f5f3fb889df","_cell_guid":"7d1260fd-1020-45fa-9a55-48f3a58bf1c2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-25T10:10:53.567335Z","iopub.execute_input":"2025-03-25T10:10:53.567768Z","iopub.status.idle":"2025-03-25T10:38:33.942518Z","shell.execute_reply.started":"2025-03-25T10:10:53.567720Z","shell.execute_reply":"2025-03-25T10:38:33.941102Z"},"papermill":{"duration":2774.531323,"end_time":"2025-03-19T19:57:30.486320","exception":false,"start_time":"2025-03-19T19:11:15.954997","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"OneHotRNN Epoch [1/70], Avg Loss: 7.5795\nOneHotRNN Epoch [2/70], Avg Loss: 6.6851\nOneHotRNN Epoch [3/70], Avg Loss: 6.3195\nOneHotRNN Epoch [4/70], Avg Loss: 6.0942\nOneHotRNN Epoch [5/70], Avg Loss: 5.9369\nOneHotRNN Epoch [6/70], Avg Loss: 5.7794\nOneHotRNN Epoch [7/70], Avg Loss: 5.6184\nOneHotRNN Epoch [8/70], Avg Loss: 5.4501\nOneHotRNN Epoch [9/70], Avg Loss: 5.2783\nOneHotRNN Epoch [10/70], Avg Loss: 5.0746\nOneHotRNN Epoch [11/70], Avg Loss: 4.8594\nOneHotRNN Epoch [12/70], Avg Loss: 4.6353\nOneHotRNN Epoch [13/70], Avg Loss: 4.3697\nOneHotRNN Epoch [14/70], Avg Loss: 4.0834\nOneHotRNN Epoch [15/70], Avg Loss: 3.8099\nOneHotRNN Epoch [16/70], Avg Loss: 3.5324\nOneHotRNN Epoch [17/70], Avg Loss: 3.2308\nOneHotRNN Epoch [18/70], Avg Loss: 2.9246\nOneHotRNN Epoch [19/70], Avg Loss: 2.6163\nOneHotRNN Epoch [20/70], Avg Loss: 2.3029\nOneHotRNN Epoch [21/70], Avg Loss: 1.9947\nOneHotRNN Epoch [22/70], Avg Loss: 1.7124\nOneHotRNN Epoch [23/70], Avg Loss: 1.4489\nOneHotRNN Epoch [24/70], Avg Loss: 1.2298\nOneHotRNN Epoch [25/70], Avg Loss: 1.0603\nOneHotRNN Epoch [26/70], Avg Loss: 0.8933\nOneHotRNN Epoch [27/70], Avg Loss: 0.7323\nOneHotRNN Epoch [28/70], Avg Loss: 0.5855\nOneHotRNN Epoch [29/70], Avg Loss: 0.4663\nOneHotRNN Epoch [30/70], Avg Loss: 0.3777\nOneHotRNN Epoch [31/70], Avg Loss: 0.3064\nOneHotRNN Epoch [32/70], Avg Loss: 0.2478\nOneHotRNN Epoch [33/70], Avg Loss: 0.2043\nOneHotRNN Epoch [34/70], Avg Loss: 0.1626\nOneHotRNN Epoch [35/70], Avg Loss: 0.1304\nOneHotRNN Epoch [36/70], Avg Loss: 0.1052\nOneHotRNN Epoch [37/70], Avg Loss: 0.0862\nOneHotRNN Epoch [38/70], Avg Loss: 0.0706\nOneHotRNN Epoch [39/70], Avg Loss: 0.0601\nOneHotRNN Epoch [40/70], Avg Loss: 0.0544\nOneHotRNN Epoch [41/70], Avg Loss: 0.0511\nOneHotRNN Epoch [42/70], Avg Loss: 0.0492\nOneHotRNN Epoch [43/70], Avg Loss: 0.0432\nOneHotRNN Epoch [44/70], Avg Loss: 0.0423\nOneHotRNN Epoch [45/70], Avg Loss: 0.0362\nOneHotRNN Epoch [46/70], Avg Loss: 0.0343\nOneHotRNN Epoch [47/70], Avg Loss: 0.0337\nOneHotRNN Epoch [48/70], Avg Loss: 0.0295\nOneHotRNN Epoch [49/70], Avg Loss: 0.0263\nOneHotRNN Epoch [50/70], Avg Loss: 0.0269\nOneHotRNN Epoch [51/70], Avg Loss: 0.0242\nOneHotRNN Epoch [52/70], Avg Loss: 0.0238\nOneHotRNN Epoch [53/70], Avg Loss: 0.0223\nOneHotRNN Epoch [54/70], Avg Loss: 0.0177\nOneHotRNN Epoch [55/70], Avg Loss: 0.0250\nOneHotRNN Epoch [56/70], Avg Loss: 0.0185\nOneHotRNN Epoch [57/70], Avg Loss: 0.0223\nOneHotRNN Epoch [58/70], Avg Loss: 0.0161\nOneHotRNN Epoch [59/70], Avg Loss: 0.0133\nOneHotRNN Epoch [60/70], Avg Loss: 0.0197\nOneHotRNN Epoch [61/70], Avg Loss: 0.0148\nOneHotRNN Epoch [62/70], Avg Loss: 0.0114\nOneHotRNN Epoch [63/70], Avg Loss: 0.0230\nOneHotRNN Epoch [64/70], Avg Loss: 0.0177\nOneHotRNN Epoch [65/70], Avg Loss: 0.0150\nOneHotRNN Epoch [66/70], Avg Loss: 0.0151\nOneHotRNN Epoch [67/70], Avg Loss: 0.0151\nOneHotRNN Epoch [68/70], Avg Loss: 0.0104\nOneHotRNN Epoch [69/70], Avg Loss: 0.0119\nOneHotRNN Epoch [70/70], Avg Loss: 0.0203\nOneHotRNN Training Time: 1660.37s\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"seed_text = \"O my Luve\"\nprint(\"\\nGenerated Poem (OneHotRNN):\", generate_poem(onehot_rnn, seed_text, model_type=\"OneHotRNN\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T10:38:33.944074Z","iopub.execute_input":"2025-03-25T10:38:33.944450Z","iopub.status.idle":"2025-03-25T10:38:34.044659Z","shell.execute_reply.started":"2025-03-25T10:38:33.944420Z","shell.execute_reply":"2025-03-25T10:38:34.043564Z"}},"outputs":[{"name":"stdout","text":"\nGenerated Poem (OneHotRNN): O my Luve And of one while I felt the wind of my day and lips. My last peal the spring beauty, and she Ride, gone goes for every object When in the mouth, arms who And make for something of day, The blood. of flowing Under my eye? When will the wind\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"train_model(onehot_lstm, onehot_lstm_optimizer, \"OneHotLSTM\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T10:38:34.046315Z","iopub.execute_input":"2025-03-25T10:38:34.046658Z","iopub.status.idle":"2025-03-25T12:49:24.846694Z","shell.execute_reply.started":"2025-03-25T10:38:34.046628Z","shell.execute_reply":"2025-03-25T12:49:24.845260Z"}},"outputs":[{"name":"stdout","text":"OneHotLSTM Epoch [1/70], Avg Loss: 7.5810\nOneHotLSTM Epoch [2/70], Avg Loss: 6.6967\nOneHotLSTM Epoch [3/70], Avg Loss: 6.3477\nOneHotLSTM Epoch [4/70], Avg Loss: 6.1494\nOneHotLSTM Epoch [5/70], Avg Loss: 6.0195\nOneHotLSTM Epoch [6/70], Avg Loss: 5.7739\nOneHotLSTM Epoch [7/70], Avg Loss: 5.5545\nOneHotLSTM Epoch [8/70], Avg Loss: 5.3069\nOneHotLSTM Epoch [9/70], Avg Loss: 5.0388\nOneHotLSTM Epoch [10/70], Avg Loss: 4.7891\nOneHotLSTM Epoch [11/70], Avg Loss: 4.5427\nOneHotLSTM Epoch [12/70], Avg Loss: 4.3147\nOneHotLSTM Epoch [13/70], Avg Loss: 4.0733\nOneHotLSTM Epoch [14/70], Avg Loss: 3.7760\nOneHotLSTM Epoch [15/70], Avg Loss: 3.4339\nOneHotLSTM Epoch [16/70], Avg Loss: 3.0609\nOneHotLSTM Epoch [17/70], Avg Loss: 2.6577\nOneHotLSTM Epoch [18/70], Avg Loss: 2.3469\nOneHotLSTM Epoch [19/70], Avg Loss: 2.1408\nOneHotLSTM Epoch [20/70], Avg Loss: 1.8252\nOneHotLSTM Epoch [21/70], Avg Loss: 1.5195\nOneHotLSTM Epoch [22/70], Avg Loss: 1.2210\nOneHotLSTM Epoch [23/70], Avg Loss: 0.9860\nOneHotLSTM Epoch [24/70], Avg Loss: 0.8061\nOneHotLSTM Epoch [25/70], Avg Loss: 0.6677\nOneHotLSTM Epoch [26/70], Avg Loss: 0.5411\nOneHotLSTM Epoch [27/70], Avg Loss: 0.4261\nOneHotLSTM Epoch [28/70], Avg Loss: 0.3242\nOneHotLSTM Epoch [29/70], Avg Loss: 0.2456\nOneHotLSTM Epoch [30/70], Avg Loss: 0.1917\nOneHotLSTM Epoch [31/70], Avg Loss: 0.1482\nOneHotLSTM Epoch [32/70], Avg Loss: 0.1211\nOneHotLSTM Epoch [33/70], Avg Loss: 0.0900\nOneHotLSTM Epoch [34/70], Avg Loss: 0.0723\nOneHotLSTM Epoch [35/70], Avg Loss: 0.0591\nOneHotLSTM Epoch [36/70], Avg Loss: 0.0478\nOneHotLSTM Epoch [37/70], Avg Loss: 0.0391\nOneHotLSTM Epoch [38/70], Avg Loss: 0.0324\nOneHotLSTM Epoch [39/70], Avg Loss: 0.0275\nOneHotLSTM Epoch [40/70], Avg Loss: 0.0230\nOneHotLSTM Epoch [41/70], Avg Loss: 0.0208\nOneHotLSTM Epoch [42/70], Avg Loss: 0.0165\nOneHotLSTM Epoch [43/70], Avg Loss: 0.0124\nOneHotLSTM Epoch [44/70], Avg Loss: 0.0122\nOneHotLSTM Epoch [45/70], Avg Loss: 0.0093\nOneHotLSTM Epoch [46/70], Avg Loss: 0.0077\nOneHotLSTM Epoch [47/70], Avg Loss: 0.0105\nOneHotLSTM Epoch [48/70], Avg Loss: 0.0111\nOneHotLSTM Epoch [49/70], Avg Loss: 0.0078\nOneHotLSTM Epoch [50/70], Avg Loss: 0.0067\nOneHotLSTM Epoch [51/70], Avg Loss: 0.0055\nOneHotLSTM Epoch [52/70], Avg Loss: 0.0066\nOneHotLSTM Epoch [53/70], Avg Loss: 0.0063\nOneHotLSTM Epoch [54/70], Avg Loss: 0.0054\nOneHotLSTM Epoch [55/70], Avg Loss: 0.0058\nOneHotLSTM Epoch [56/70], Avg Loss: 0.0042\nOneHotLSTM Epoch [57/70], Avg Loss: 0.0038\nOneHotLSTM Epoch [58/70], Avg Loss: 0.0038\nOneHotLSTM Epoch [59/70], Avg Loss: 0.0036\nOneHotLSTM Epoch [60/70], Avg Loss: 0.0036\nOneHotLSTM Epoch [61/70], Avg Loss: 0.0023\nOneHotLSTM Epoch [62/70], Avg Loss: 0.0015\nOneHotLSTM Epoch [63/70], Avg Loss: 0.0011\nOneHotLSTM Epoch [64/70], Avg Loss: 0.0043\nOneHotLSTM Epoch [65/70], Avg Loss: 0.0034\nOneHotLSTM Epoch [66/70], Avg Loss: 0.0046\nOneHotLSTM Epoch [67/70], Avg Loss: 0.0035\nOneHotLSTM Epoch [68/70], Avg Loss: 0.0020\nOneHotLSTM Epoch [69/70], Avg Loss: 0.0016\nOneHotLSTM Epoch [70/70], Avg Loss: 0.0013\nOneHotLSTM Training Time: 7850.79s\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(\"\\nGenerated Poem (OneHotLSTM):\", generate_poem(onehot_lstm, seed_text, model_type=\"OneHotLSTM\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:49:24.848674Z","iopub.execute_input":"2025-03-25T12:49:24.849044Z","iopub.status.idle":"2025-03-25T12:49:25.162350Z","shell.execute_reply.started":"2025-03-25T12:49:24.849003Z","shell.execute_reply":"2025-03-25T12:49:25.161225Z"}},"outputs":[{"name":"stdout","text":"\nGenerated Poem (OneHotLSTM): O my Luve rest click left,) headstone foreign, missing, none more looking Thou dost smile, I sing the while, Sweet joy befall thee! The city had withdrawn into itself And left at last the country to the country; When between whirls of snow not come to lie And whirls of foliage not yet\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"train_model(embedding_rnn, embedding_rnn_optimizer, \"EmbeddingRNN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:49:25.163707Z","iopub.execute_input":"2025-03-25T12:49:25.164103Z","iopub.status.idle":"2025-03-25T13:02:16.897577Z","shell.execute_reply.started":"2025-03-25T12:49:25.164072Z","shell.execute_reply":"2025-03-25T13:02:16.896353Z"}},"outputs":[{"name":"stdout","text":"EmbeddingRNN Epoch [1/70], Avg Loss: 7.5929\nEmbeddingRNN Epoch [2/70], Avg Loss: 6.3903\nEmbeddingRNN Epoch [3/70], Avg Loss: 5.7654\nEmbeddingRNN Epoch [4/70], Avg Loss: 5.2057\nEmbeddingRNN Epoch [5/70], Avg Loss: 4.7298\nEmbeddingRNN Epoch [6/70], Avg Loss: 4.2991\nEmbeddingRNN Epoch [7/70], Avg Loss: 3.7787\nEmbeddingRNN Epoch [8/70], Avg Loss: 3.2889\nEmbeddingRNN Epoch [9/70], Avg Loss: 2.9054\nEmbeddingRNN Epoch [10/70], Avg Loss: 2.5815\nEmbeddingRNN Epoch [11/70], Avg Loss: 2.2945\nEmbeddingRNN Epoch [12/70], Avg Loss: 2.0746\nEmbeddingRNN Epoch [13/70], Avg Loss: 1.9019\nEmbeddingRNN Epoch [14/70], Avg Loss: 1.6860\nEmbeddingRNN Epoch [15/70], Avg Loss: 1.4679\nEmbeddingRNN Epoch [16/70], Avg Loss: 1.2722\nEmbeddingRNN Epoch [17/70], Avg Loss: 1.1039\nEmbeddingRNN Epoch [18/70], Avg Loss: 0.9583\nEmbeddingRNN Epoch [19/70], Avg Loss: 0.8286\nEmbeddingRNN Epoch [20/70], Avg Loss: 0.7190\nEmbeddingRNN Epoch [21/70], Avg Loss: 0.6269\nEmbeddingRNN Epoch [22/70], Avg Loss: 0.5413\nEmbeddingRNN Epoch [23/70], Avg Loss: 0.4739\nEmbeddingRNN Epoch [24/70], Avg Loss: 0.4185\nEmbeddingRNN Epoch [25/70], Avg Loss: 0.3674\nEmbeddingRNN Epoch [26/70], Avg Loss: 0.3213\nEmbeddingRNN Epoch [27/70], Avg Loss: 0.2783\nEmbeddingRNN Epoch [28/70], Avg Loss: 0.2446\nEmbeddingRNN Epoch [29/70], Avg Loss: 0.2157\nEmbeddingRNN Epoch [30/70], Avg Loss: 0.1927\nEmbeddingRNN Epoch [31/70], Avg Loss: 0.1728\nEmbeddingRNN Epoch [32/70], Avg Loss: 0.1653\nEmbeddingRNN Epoch [33/70], Avg Loss: 0.1514\nEmbeddingRNN Epoch [34/70], Avg Loss: 0.1335\nEmbeddingRNN Epoch [35/70], Avg Loss: 0.1300\nEmbeddingRNN Epoch [36/70], Avg Loss: 0.1198\nEmbeddingRNN Epoch [37/70], Avg Loss: 0.1131\nEmbeddingRNN Epoch [38/70], Avg Loss: 0.1068\nEmbeddingRNN Epoch [39/70], Avg Loss: 0.1051\nEmbeddingRNN Epoch [40/70], Avg Loss: 0.0930\nEmbeddingRNN Epoch [41/70], Avg Loss: 0.0783\nEmbeddingRNN Epoch [42/70], Avg Loss: 0.0742\nEmbeddingRNN Epoch [43/70], Avg Loss: 0.0871\nEmbeddingRNN Epoch [44/70], Avg Loss: 0.0831\nEmbeddingRNN Epoch [45/70], Avg Loss: 0.0825\nEmbeddingRNN Epoch [46/70], Avg Loss: 0.0740\nEmbeddingRNN Epoch [47/70], Avg Loss: 0.0647\nEmbeddingRNN Epoch [48/70], Avg Loss: 0.0632\nEmbeddingRNN Epoch [49/70], Avg Loss: 0.0694\nEmbeddingRNN Epoch [50/70], Avg Loss: 0.0703\nEmbeddingRNN Epoch [51/70], Avg Loss: 0.0701\nEmbeddingRNN Epoch [52/70], Avg Loss: 0.0622\nEmbeddingRNN Epoch [53/70], Avg Loss: 0.0534\nEmbeddingRNN Epoch [54/70], Avg Loss: 0.0497\nEmbeddingRNN Epoch [55/70], Avg Loss: 0.0533\nEmbeddingRNN Epoch [56/70], Avg Loss: 0.0520\nEmbeddingRNN Epoch [57/70], Avg Loss: 0.0509\nEmbeddingRNN Epoch [58/70], Avg Loss: 0.0551\nEmbeddingRNN Epoch [59/70], Avg Loss: 0.0527\nEmbeddingRNN Epoch [60/70], Avg Loss: 0.0536\nEmbeddingRNN Epoch [61/70], Avg Loss: 0.0451\nEmbeddingRNN Epoch [62/70], Avg Loss: 0.0448\nEmbeddingRNN Epoch [63/70], Avg Loss: 0.0451\nEmbeddingRNN Epoch [64/70], Avg Loss: 0.0427\nEmbeddingRNN Epoch [65/70], Avg Loss: 0.0416\nEmbeddingRNN Epoch [66/70], Avg Loss: 0.0458\nEmbeddingRNN Epoch [67/70], Avg Loss: 0.0480\nEmbeddingRNN Epoch [68/70], Avg Loss: 0.0419\nEmbeddingRNN Epoch [69/70], Avg Loss: 0.0330\nEmbeddingRNN Epoch [70/70], Avg Loss: 0.0245\nEmbeddingRNN Training Time: 771.73s\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"print(\"\\nGenerated Poem (EmbeddingRNN):\", generate_poem(embedding_rnn, seed_text, model_type=\"EmbeddingRNN\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:02:16.898942Z","iopub.execute_input":"2025-03-25T13:02:16.899347Z","iopub.status.idle":"2025-03-25T13:02:16.948558Z","shell.execute_reply.started":"2025-03-25T13:02:16.899303Z","shell.execute_reply":"2025-03-25T13:02:16.947430Z"}},"outputs":[{"name":"stdout","text":"\nGenerated Poem (EmbeddingRNN): O my Luve and Oh, I can my good will, Scattering it freely forever. The pure contralto sings in the organ loft, The carpenter dresses his plank, the tongue of his foreplane whistles its wild ascending lisp, The married and unmarried children ride home to their Thanksgiving dinner, The pilot seizes the king-pin,\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"train_model(embedding_lstm, embedding_lstm_optimizer, \"EmbeddingLSTM\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:02:16.949548Z","iopub.execute_input":"2025-03-25T13:02:16.949925Z","iopub.status.idle":"2025-03-25T13:17:33.263914Z","shell.execute_reply.started":"2025-03-25T13:02:16.949892Z","shell.execute_reply":"2025-03-25T13:17:33.262743Z"}},"outputs":[{"name":"stdout","text":"EmbeddingLSTM Epoch [1/70], Avg Loss: 7.5631\nEmbeddingLSTM Epoch [2/70], Avg Loss: 6.5433\nEmbeddingLSTM Epoch [3/70], Avg Loss: 5.9872\nEmbeddingLSTM Epoch [4/70], Avg Loss: 5.4844\nEmbeddingLSTM Epoch [5/70], Avg Loss: 4.9963\nEmbeddingLSTM Epoch [6/70], Avg Loss: 4.5167\nEmbeddingLSTM Epoch [7/70], Avg Loss: 4.1496\nEmbeddingLSTM Epoch [8/70], Avg Loss: 3.7315\nEmbeddingLSTM Epoch [9/70], Avg Loss: 3.2990\nEmbeddingLSTM Epoch [10/70], Avg Loss: 2.9829\nEmbeddingLSTM Epoch [11/70], Avg Loss: 2.6195\nEmbeddingLSTM Epoch [12/70], Avg Loss: 2.2721\nEmbeddingLSTM Epoch [13/70], Avg Loss: 1.9076\nEmbeddingLSTM Epoch [14/70], Avg Loss: 1.5767\nEmbeddingLSTM Epoch [15/70], Avg Loss: 1.2990\nEmbeddingLSTM Epoch [16/70], Avg Loss: 1.0700\nEmbeddingLSTM Epoch [17/70], Avg Loss: 0.8783\nEmbeddingLSTM Epoch [18/70], Avg Loss: 0.7216\nEmbeddingLSTM Epoch [19/70], Avg Loss: 0.6034\nEmbeddingLSTM Epoch [20/70], Avg Loss: 0.4990\nEmbeddingLSTM Epoch [21/70], Avg Loss: 0.4168\nEmbeddingLSTM Epoch [22/70], Avg Loss: 0.3512\nEmbeddingLSTM Epoch [23/70], Avg Loss: 0.3000\nEmbeddingLSTM Epoch [24/70], Avg Loss: 0.2630\nEmbeddingLSTM Epoch [25/70], Avg Loss: 0.2354\nEmbeddingLSTM Epoch [26/70], Avg Loss: 0.2202\nEmbeddingLSTM Epoch [27/70], Avg Loss: 0.2146\nEmbeddingLSTM Epoch [28/70], Avg Loss: 0.2084\nEmbeddingLSTM Epoch [29/70], Avg Loss: 0.2086\nEmbeddingLSTM Epoch [30/70], Avg Loss: 0.2102\nEmbeddingLSTM Epoch [31/70], Avg Loss: 0.2792\nEmbeddingLSTM Epoch [32/70], Avg Loss: 0.3495\nEmbeddingLSTM Epoch [33/70], Avg Loss: 0.2783\nEmbeddingLSTM Epoch [34/70], Avg Loss: 0.1083\nEmbeddingLSTM Epoch [35/70], Avg Loss: 0.0512\nEmbeddingLSTM Epoch [36/70], Avg Loss: 0.0295\nEmbeddingLSTM Epoch [37/70], Avg Loss: 0.0196\nEmbeddingLSTM Epoch [38/70], Avg Loss: 0.0140\nEmbeddingLSTM Epoch [39/70], Avg Loss: 0.0105\nEmbeddingLSTM Epoch [40/70], Avg Loss: 0.0092\nEmbeddingLSTM Epoch [41/70], Avg Loss: 0.1872\nEmbeddingLSTM Epoch [42/70], Avg Loss: 0.1801\nEmbeddingLSTM Epoch [43/70], Avg Loss: 0.0505\nEmbeddingLSTM Epoch [44/70], Avg Loss: 0.0177\nEmbeddingLSTM Epoch [45/70], Avg Loss: 0.0092\nEmbeddingLSTM Epoch [46/70], Avg Loss: 0.0066\nEmbeddingLSTM Epoch [47/70], Avg Loss: 0.0054\nEmbeddingLSTM Epoch [48/70], Avg Loss: 0.0040\nEmbeddingLSTM Epoch [49/70], Avg Loss: 0.0048\nEmbeddingLSTM Epoch [50/70], Avg Loss: 0.1644\nEmbeddingLSTM Epoch [51/70], Avg Loss: 0.0958\nEmbeddingLSTM Epoch [52/70], Avg Loss: 0.0243\nEmbeddingLSTM Epoch [53/70], Avg Loss: 0.0083\nEmbeddingLSTM Epoch [54/70], Avg Loss: 0.0046\nEmbeddingLSTM Epoch [55/70], Avg Loss: 0.0033\nEmbeddingLSTM Epoch [56/70], Avg Loss: 0.0025\nEmbeddingLSTM Epoch [57/70], Avg Loss: 0.0019\nEmbeddingLSTM Epoch [58/70], Avg Loss: 0.0015\nEmbeddingLSTM Epoch [59/70], Avg Loss: 0.0011\nEmbeddingLSTM Epoch [60/70], Avg Loss: 0.0009\nEmbeddingLSTM Epoch [61/70], Avg Loss: 0.0007\nEmbeddingLSTM Epoch [62/70], Avg Loss: 0.0005\nEmbeddingLSTM Epoch [63/70], Avg Loss: 0.0004\nEmbeddingLSTM Epoch [64/70], Avg Loss: 0.0003\nEmbeddingLSTM Epoch [65/70], Avg Loss: 0.0097\nEmbeddingLSTM Epoch [66/70], Avg Loss: 0.2967\nEmbeddingLSTM Epoch [67/70], Avg Loss: 0.0691\nEmbeddingLSTM Epoch [68/70], Avg Loss: 0.0151\nEmbeddingLSTM Epoch [69/70], Avg Loss: 0.0056\nEmbeddingLSTM Epoch [70/70], Avg Loss: 0.0033\nEmbeddingLSTM Training Time: 916.31s\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"print(\"\\nGenerated Poem (EmbeddingLSTM):\", generate_poem(embedding_lstm, seed_text, model_type=\"EmbeddingLSTM\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:17:33.266393Z","iopub.execute_input":"2025-03-25T13:17:33.266753Z","iopub.status.idle":"2025-03-25T13:17:33.324056Z","shell.execute_reply.started":"2025-03-25T13:17:33.266722Z","shell.execute_reply":"2025-03-25T13:17:33.323039Z"}},"outputs":[{"name":"stdout","text":"\nGenerated Poem (EmbeddingLSTM): O my Luve and space, And that is enough, Through the past is the clock came out for good strong I rock It was not lost listening to you, or whole Or I guess it is a uniform hieroglyphic, And it means, Sprouting alike in broad zones and narrow zones, Growing among black\n","output_type":"stream"}],"execution_count":25}]}