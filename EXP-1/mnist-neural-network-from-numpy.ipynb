{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":242592,"sourceType":"datasetVersion","datasetId":102285},{"sourceId":6191570,"sourceType":"datasetVersion","datasetId":3553967}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from os.path import join\nimport matplotlib.pyplot as plt\nimport numpy as np\nimage_dim = 28\n\ninput_path = '/kaggle/input/mnist-dataset'\ntrain_image_path = join(input_path, 'train-images.idx3-ubyte')\ntrain_labels_path = join(input_path, 'train-labels.idx1-ubyte')\ntest_image_path = join(input_path, 't10k-images.idx3-ubyte')\ntest_labels_path = join(input_path, 't10k-labels.idx1-ubyte')\n\n''' \nimage is saved in a byte stream sequentially\nfirst 16 for header remaining 28 * 28 pixels of each image in sequence for 60000 images\n'''\n\nwith open(train_image_path, 'rb') as file: \n    data = np.frombuffer(file.read(), dtype = np.uint8)\n\nwith open(train_labels_path, 'rb') as file:\n    labels = np.frombuffer(file.read(), dtype = np.uint8)\n        \nlabels = labels[8:]\nprint(labels.shape)\n\nimages = data[16:].reshape(-1,image_dim, image_dim) # original size is also (28, 28)\nprint(images.shape)\n\nplt.imshow(images[1], cmap=\"gray\")\nplt.title(\"First Image\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T17:34:27.879136Z","iopub.execute_input":"2025-01-15T17:34:27.879456Z","iopub.status.idle":"2025-01-15T17:34:28.196008Z","shell.execute_reply.started":"2025-01-15T17:34:27.879415Z","shell.execute_reply":"2025-01-15T17:34:28.194777Z"}},"outputs":[{"name":"stdout","text":"(60000,)\n(60000, 28, 28)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"class MNIST_Dataloader:\n    def __init__(self, train_image_path, train_labels_path, test_image_path, test_labels_path, dim):\n        \"\"\"\n        Initialize the MNIST dataloader.\n        :param train_image_path: Path to the training images.\n        :param train_labels_path: Path to the training labels.\n        :param test_image_path: Path to the test images.\n        :param test_labels_path: Path to the test labels.\n        :param dim: Dimension of the images (e.g., 28 for 28x28 images).\n        :param preprocessors: List of preprocessing functions to apply to the images.\n        \"\"\"\n        self.train_image_path = train_image_path\n        self.train_labels_path = train_labels_path\n        self.test_image_path = test_image_path\n        self.test_labels_path = test_labels_path\n        self.dim = dim\n\n    def read_image_labels(self, image_path, label_path):\n        with open(image_path, 'rb') as file:\n            images = np.frombuffer(file.read(), dtype=np.uint8)\n\n        # Reshape and normalize images\n        images = images[16:].reshape(-1, self.dim, self.dim).astype(np.float32)\n        images /= 255.0  # Normalize to range [0, 1]\n\n        with open(label_path, 'rb') as file:\n            labels = np.frombuffer(file.read(), dtype=np.uint8)\n\n        # One-hot encode labels\n        one_hot_labels = np.eye(10)[labels[8:]]\n\n        return images, one_hot_labels\n\n    def load_data(self):\n        \"\"\"\n        Load the MNIST data.\n        :return: Tuple containing train and test datasets.\n        \"\"\"\n        train_images, train_labels = self.read_image_labels(self.train_image_path, self.train_labels_path)\n        test_images, test_labels = self.read_image_labels(self.test_image_path, self.test_labels_path)\n\n        # Flatten images back to 1D after preprocessing\n        train_images = train_images.reshape(-1, self.dim**2)\n        test_images = test_images.reshape(-1, self.dim**2)\n\n        return (train_images, train_labels), (test_images, test_labels)\n\n\ndobj = MNIST_Dataloader(train_image_path, train_labels_path, test_image_path, test_labels_path, image_dim)\n\n(train_images, train_labels), (test_images, test_labels) = dobj.load_data()\nsplit_ratio = 0.2\nsplit_index = int(len(train_images) * split_ratio)\ntrain_images, train_labels = train_images[split_index:], train_labels[split_index:]\nval_images, val_labels = train_images[:split_index], train_labels[:split_index]\n\nprint(train_images.shape, train_labels.shape)\nprint(val_images.shape, val_labels.shape)\nprint(test_images.shape, test_labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T17:34:28.197466Z","iopub.execute_input":"2025-01-15T17:34:28.197929Z","iopub.status.idle":"2025-01-15T17:34:28.351143Z","shell.execute_reply.started":"2025-01-15T17:34:28.197878Z","shell.execute_reply":"2025-01-15T17:34:28.349921Z"}},"outputs":[{"name":"stdout","text":"(48000, 784) (48000, 10)\n(12000, 784) (12000, 10)\n(10000, 784) (10000, 10)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class FullyConnectedNN:\n    def __init__(self, layers):\n        self.layers = layers\n        self.weights = []\n        self.biases = []\n        self.best_loss = float('inf')  # Initialize with a high value\n        \n        # Initialize weights and biases using He initialization\n        for i in range(len(layers) - 1):\n            self.weights.append(np.random.randn(layers[i], layers[i + 1]) * np.sqrt(2 / layers[i]))\n            self.biases.append(np.zeros((1, layers[i + 1])))\n\n    def relu(self, z):\n        return np.maximum(0, z)\n\n    def relu_derivative(self, z):\n        return np.where(z > 0, 1, 0)\n\n    def softmax(self, z):\n        # Check for NaN or Inf in z before applying softmax\n        if np.any(np.isnan(z)) or np.any(np.isinf(z)):\n            print(\"Warning: NaN or Inf detected in z before softmax.\")\n        z_stable = z - np.max(z, axis=1, keepdims=True)  # Stability improvement\n        exp_z = np.exp(z_stable)\n        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n\n    def feedforward(self, X, training=True):\n        activations = [X]\n        for i in range(len(self.weights)):\n            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n            if i == len(self.weights) - 1:  # Output layer\n                a = self.softmax(z)\n            else:  # Hidden layers\n                a = self.relu(z)\n            activations.append(a)\n        return activations\n\n    def backpropagation(self, X, y, learning_rate):\n        activations = self.feedforward(X, training=True)\n        deltas = [activations[-1] - y]\n\n        for i in range(len(self.layers) - 2, 0, -1):\n            delta = np.dot(deltas[-1], self.weights[i].T)\n            delta *= self.relu_derivative(activations[i])\n            deltas.append(delta)\n\n        deltas.reverse()\n\n        for i in range(len(self.weights)):\n            # Update weights and biases with gradient clipping\n            grad_w = np.dot(activations[i].T, deltas[i])\n            grad_b = np.sum(deltas[i], axis=0, keepdims=True)\n            grad_w = np.clip(grad_w, -2.0, 2.0)  # Clip gradients to prevent explosion\n            grad_b = np.clip(grad_b, -2.0, 2.0)\n            self.weights[i] -= learning_rate * grad_w\n            self.biases[i] -= learning_rate * grad_b\n\n    def train(self, X, y, X_val, y_val, epochs, learning_rate):\n        for epoch in range(epochs):\n            self.backpropagation(X, y, learning_rate)\n            train_loss = self.calculate_loss(X, y)\n            val_loss = self.calculate_loss(X_val, y_val)\n            accuracy = self.calculate_accuracy(X_val, y_val)\n\n            # Save the best weights based on validation loss\n            if val_loss < self.best_loss:\n                self.best_loss = val_loss\n                best_weights = [w.copy() for w in self.weights]\n                best_biases = [b.copy() for b in self.biases]\n                print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n                self.save_best_weights('best_weights.npy', best_weights, best_biases)\n\n            if epoch % 100 == 0:\n                print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n\n    def predict(self, X):\n        return self.feedforward(X, training=False)[-1]\n\n    def calculate_loss(self, X, y):\n        predictions = self.predict(X)\n        # Add epsilon to avoid log(0)\n        return -np.mean(np.sum(y * np.log(predictions + 1e-8), axis=1))\n\n    def calculate_accuracy(self, X, y):\n        predictions = self.predict(X)\n        predicted_labels = np.argmax(predictions, axis=1)\n        true_labels = np.argmax(y, axis=1)\n        return np.mean(predicted_labels == true_labels)\n\n    def save_best_weights(self, filepath, best_weights, best_biases):\n        np.save(filepath, {'weights': best_weights, 'biases': best_biases})\n        print(\"Best weights saved to disk.\")\n\n    def load_weights(self, filepath):\n        data = np.load(filepath, allow_pickle=True).item()\n        self.weights = data['weights']\n        self.biases = data['biases']\n        print(\"Best weights loaded from disk.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T17:34:28.352372Z","iopub.execute_input":"2025-01-15T17:34:28.352772Z","iopub.status.idle":"2025-01-15T17:34:28.370596Z","shell.execute_reply.started":"2025-01-15T17:34:28.352732Z","shell.execute_reply":"2025-01-15T17:34:28.369019Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Define network structure: 784 input neurons, 1 hidden layers with 128 neurons each, and 10 output neuron\nlayers = [image_dim ** 2, 256, 128, 10]\n\n# Calculate the number of trainable parameters in the network\nparams = 0\nfor i in range(len(layers) - 1): \n    if i == 0:\n        params += layers[i] * image_dim ** 2\n    else:\n        params += layers[i] * layers[i - 1]\n\nprint(\"Total trainable parameters:\", params)\n\n# Create the neural network\nnn = FullyConnectedNN(layers)\n\n# Train the network (use train_images and train_labels)\nnn.train(train_images, train_labels, val_images, val_labels, epochs=400, learning_rate=0.005)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T17:35:06.116097Z","iopub.execute_input":"2025-01-15T17:35:06.116509Z","iopub.status.idle":"2025-01-15T17:55:41.277897Z","shell.execute_reply.started":"2025-01-15T17:35:06.116473Z","shell.execute_reply":"2025-01-15T17:55:41.275809Z"}},"outputs":[{"name":"stdout","text":"Total trainable parameters: 848128\nEpoch 0, Train Loss: 1.7760, Val Loss: 1.8006, Accuracy: 0.4602\nBest weights saved to disk.\nEpoch 0, Train Loss: 1.7760, Val Loss: 1.8006, Accuracy: 0.4602\nEpoch 7, Train Loss: 1.3428, Val Loss: 1.3587, Accuracy: 0.5678\nBest weights saved to disk.\nEpoch 9, Train Loss: 1.2905, Val Loss: 1.3029, Accuracy: 0.6654\nBest weights saved to disk.\nEpoch 11, Train Loss: 1.0047, Val Loss: 1.0035, Accuracy: 0.6786\nBest weights saved to disk.\nEpoch 13, Train Loss: 1.0055, Val Loss: 0.9993, Accuracy: 0.6877\nBest weights saved to disk.\nEpoch 23, Train Loss: 0.9911, Val Loss: 0.9840, Accuracy: 0.7436\nBest weights saved to disk.\nEpoch 25, Train Loss: 0.9649, Val Loss: 0.9642, Accuracy: 0.7652\nBest weights saved to disk.\nEpoch 38, Train Loss: 0.9161, Val Loss: 0.9208, Accuracy: 0.7733\nBest weights saved to disk.\nEpoch 40, Train Loss: 0.8554, Val Loss: 0.8616, Accuracy: 0.7891\nBest weights saved to disk.\nEpoch 42, Train Loss: 0.8284, Val Loss: 0.8282, Accuracy: 0.7950\nBest weights saved to disk.\nEpoch 61, Train Loss: 0.8215, Val Loss: 0.8103, Accuracy: 0.8079\nBest weights saved to disk.\nEpoch 63, Train Loss: 0.7515, Val Loss: 0.7419, Accuracy: 0.8184\nBest weights saved to disk.\nEpoch 65, Train Loss: 0.6986, Val Loss: 0.6927, Accuracy: 0.8277\nBest weights saved to disk.\nEpoch 67, Train Loss: 0.6579, Val Loss: 0.6595, Accuracy: 0.8352\nBest weights saved to disk.\nEpoch 69, Train Loss: 0.6164, Val Loss: 0.6293, Accuracy: 0.8463\nBest weights saved to disk.\nEpoch 99, Train Loss: 0.6008, Val Loss: 0.5998, Accuracy: 0.8666\nBest weights saved to disk.\nEpoch 100, Train Loss: 0.7032, Val Loss: 0.7163, Accuracy: 0.8486\nEpoch 137, Train Loss: 0.6012, Val Loss: 0.5890, Accuracy: 0.8904\nBest weights saved to disk.\nEpoch 139, Train Loss: 0.5781, Val Loss: 0.5642, Accuracy: 0.8944\nBest weights saved to disk.\nEpoch 171, Train Loss: 0.5424, Val Loss: 0.5463, Accuracy: 0.9124\nBest weights saved to disk.\nEpoch 173, Train Loss: 0.5264, Val Loss: 0.5283, Accuracy: 0.9143\nBest weights saved to disk.\nEpoch 179, Train Loss: 0.5329, Val Loss: 0.5094, Accuracy: 0.8969\nBest weights saved to disk.\nEpoch 200, Train Loss: 0.5048, Val Loss: 0.5242, Accuracy: 0.9107\nEpoch 264, Train Loss: 0.4998, Val Loss: 0.4986, Accuracy: 0.9230\nBest weights saved to disk.\nEpoch 266, Train Loss: 0.4870, Val Loss: 0.4856, Accuracy: 0.9257\nBest weights saved to disk.\nEpoch 280, Train Loss: 0.4620, Val Loss: 0.4797, Accuracy: 0.9297\nBest weights saved to disk.\nEpoch 282, Train Loss: 0.4435, Val Loss: 0.4589, Accuracy: 0.9322\nBest weights saved to disk.\nEpoch 284, Train Loss: 0.4358, Val Loss: 0.4421, Accuracy: 0.9333\nBest weights saved to disk.\nEpoch 300, Train Loss: 0.4850, Val Loss: 0.4555, Accuracy: 0.9337\nEpoch 302, Train Loss: 0.4712, Val Loss: 0.4399, Accuracy: 0.9349\nBest weights saved to disk.\nEpoch 304, Train Loss: 0.4568, Val Loss: 0.4257, Accuracy: 0.9371\nBest weights saved to disk.\nEpoch 306, Train Loss: 0.4435, Val Loss: 0.4140, Accuracy: 0.9383\nBest weights saved to disk.\nEpoch 308, Train Loss: 0.4320, Val Loss: 0.4053, Accuracy: 0.9382\nBest weights saved to disk.\nEpoch 310, Train Loss: 0.4227, Val Loss: 0.3983, Accuracy: 0.9384\nBest weights saved to disk.\nEpoch 312, Train Loss: 0.4152, Val Loss: 0.3926, Accuracy: 0.9394\nBest weights saved to disk.\nEpoch 314, Train Loss: 0.4008, Val Loss: 0.3790, Accuracy: 0.9423\nBest weights saved to disk.\nEpoch 316, Train Loss: 0.3926, Val Loss: 0.3740, Accuracy: 0.9439\nBest weights saved to disk.\nEpoch 328, Train Loss: 0.3848, Val Loss: 0.3677, Accuracy: 0.9456\nBest weights saved to disk.\nEpoch 330, Train Loss: 0.3756, Val Loss: 0.3566, Accuracy: 0.9460\nBest weights saved to disk.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"nn.load_weights('best_weights.npy')\naccuracy = nn.calculate_accuracy(test_images, test_labels)\nloss = nn.calculate_loss(test_images, test_labels)\n\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Test Loss: {loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T17:55:41.279573Z","iopub.execute_input":"2025-01-15T17:55:41.280113Z","iopub.status.idle":"2025-01-15T17:55:41.660739Z","shell.execute_reply.started":"2025-01-15T17:55:41.280063Z","shell.execute_reply":"2025-01-15T17:55:41.658244Z"}},"outputs":[{"name":"stdout","text":"Best weights loaded from disk.\nTest Accuracy: 92.81%\nTest Loss: 0.5028302131428092\n","output_type":"stream"}],"execution_count":6}]}